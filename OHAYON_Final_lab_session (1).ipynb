{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OHAYON - Final lab session.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwD6FGAZQrpm",
        "colab_type": "text"
      },
      "source": [
        "# Final lab session\n",
        "\n",
        "\n",
        "Fill with your information:\n",
        "* First name: Eddy \n",
        "* Last name: OHAYON\n",
        "* email: eddy.ohayon5@gmail.com \n",
        "\n",
        "# Description\n",
        "\n",
        "For this lab session, you will have to code in Python using `keras`. \n",
        "You will have to learn about the so-called [functional API](http://keras.io/getting-started/functional-api-guide/). When going through this tutorial, pay specific attention to the “Multi-input and multi-output models” and “Shared layers” sections).\n",
        "\n",
        "## Problem statement\n",
        "\n",
        "A school receives each year a given number of student applications. These applications are made both of qualitative elements (that we will ignore in this exercise) and some quantitative ones about the grades they obtained for a given list of courses the student followed.\n",
        "\n",
        "Let us assume that people in charge of the selection process in this school would like to compute, for each student, a kind of global grade that would be a weighted average of its grades.\n",
        "Unfortunately, these peolpe are not able to reach a consensus on which weights to use.\n",
        "The only consensus they could reach is when they have to compare a pair of files and decide on which is better.\n",
        "\n",
        "The goal of this assignment is then to design a model that could learn those weights based on provided pairwise comparisons. \n",
        "To do so, you are given a dataset that indicates, for each pair of student candidates, the one that would be prefered (and hence ranked higher) by the jury.\n",
        "\n",
        "Constraints for this problem are as follows:\n",
        "* the final score given to a student should be a linear combination of its grades;\n",
        "* each weight should be positive;\n",
        "* the weights should sum to 1.\n",
        "\n",
        "## Data and expected output\n",
        "\n",
        "Input data is organized in two separate files:\n",
        "* `grades.csv` provides grades for each students;\n",
        "* `compare.csv` indicates, for a given pair of students, the one that the jury would have preferred.\n",
        "\n",
        "The code below downloads these two files that you can then load using `numpy.loadtxt`\n",
        "\n",
        "You will have to provide two things on your side:\n",
        "* a completed version of this notebook (in .ipynb format);\n",
        "* a text file containing the learned weights, as generated by `numpy.savetxt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVMltXGcQk6A",
        "colab_type": "code",
        "outputId": "f6864948-ee7d-419f-d3f3-d31aa2826dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "!wget \"https://rtavenar.github.io/teaching/deep_edhec/data/project/compare.csv\"\n",
        "!wget \"https://rtavenar.github.io/teaching/deep_edhec/data/project/grades.csv\"\n",
        "!head compare.csv\n",
        "!echo \"---\"\n",
        "!head grades.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-31 14:12:44--  https://rtavenar.github.io/teaching/deep_edhec/data/project/compare.csv\n",
            "Resolving rtavenar.github.io (rtavenar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.110.153, ...\n",
            "Connecting to rtavenar.github.io (rtavenar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1466462 (1.4M) [text/csv]\n",
            "Saving to: ‘compare.csv.10’\n",
            "\n",
            "\rcompare.csv.10        0%[                    ]       0  --.-KB/s               \rcompare.csv.10      100%[===================>]   1.40M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-05-31 14:12:44 (39.4 MB/s) - ‘compare.csv.10’ saved [1466462/1466462]\n",
            "\n",
            "--2019-05-31 14:12:47--  https://rtavenar.github.io/teaching/deep_edhec/data/project/grades.csv\n",
            "Resolving rtavenar.github.io (rtavenar.github.io)... 185.199.109.153, 185.199.111.153, 185.199.110.153, ...\n",
            "Connecting to rtavenar.github.io (rtavenar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 790457 (772K) [text/csv]\n",
            "Saving to: ‘grades.csv.10’\n",
            "\n",
            "grades.csv.10       100%[===================>] 771.93K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-05-31 14:12:47 (22.9 MB/s) - ‘grades.csv.10’ saved [790457/790457]\n",
            "\n",
            "ID_ETU1;ID_ETU2;BEST_ETU\n",
            "4928;7791;7791\n",
            "4302;7448;7448\n",
            "1005;8816;1005\n",
            "1970;2533;2533\n",
            "3203;1186;1186\n",
            "3057;3928;3057\n",
            "7636;647;647\n",
            "2843;9681;2843\n",
            "1530;9920;9920\n",
            "---\n",
            "ID_ETU;MATHS;ECONOMICS;CS;ENGLISH\n",
            "0;11.327108937284375;13.660533681092723;9.648868609183825;8.948518933254707\n",
            "1;11.821354244379835;13.741515832807938;11.10487924076519;8.898336950581037\n",
            "2;10.83920044554664;11.062179511028788;9.361237395116056;9.350797211934335\n",
            "3;12.43419379217033;14.20490498479952;12.897864430771524;7.911875589045201\n",
            "4;12.3466884921927;13.967510958751477;11.233273350247824;8.017591488691615\n",
            "5;11.481883549520745;14.638864623834237;10.361781717304378;6.493702820018287\n",
            "6;12.72821110867008;13.859976183460791;10.298935562491396;7.794669194301584\n",
            "7;11.304473236533095;14.441877340177882;9.80319394090802;6.6907655396450405\n",
            "8;12.977482366792097;14.464272008859501;11.402954775901671;8.322073406639266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0isUHQv2jtU",
        "colab_type": "text"
      },
      "source": [
        "# Data loading and inspecting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEii0p4o1F9b",
        "colab_type": "text"
      },
      "source": [
        "First, we load all the libraries we will need and load the datasets as arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtikgKn4iatX",
        "colab_type": "code",
        "outputId": "1eb9de67-ca8e-4226-893d-9226da1939ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import the libraries\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import Input, Dense, LSTM, Concatenate\n",
        "from keras.models import Model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# load the datasets\n",
        "grades = np.loadtxt('grades.csv',delimiter=';',skiprows=1)\n",
        "compare = np.loadtxt('compare.csv',delimiter=';',skiprows=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haoTEGhf1jPy",
        "colab_type": "text"
      },
      "source": [
        "We have a first look at the shape and structure of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyaUFCi9m_T_",
        "colab_type": "code",
        "outputId": "2e88b09f-37aa-4516-8476-cddc5700c7e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# For the grades\n",
        "print(grades.shape)\n",
        "print(grades[:10])\n",
        "\n",
        "# For the comparisons\n",
        "print(compare.shape)\n",
        "print(compare[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 5)\n",
            "[[ 0.         11.32710894 13.66053368  9.64886861  8.94851893]\n",
            " [ 1.         11.82135424 13.74151583 11.10487924  8.89833695]\n",
            " [ 2.         10.83920045 11.06217951  9.3612374   9.35079721]\n",
            " [ 3.         12.43419379 14.20490498 12.89786443  7.91187559]\n",
            " [ 4.         12.34668849 13.96751096 11.23327335  8.01759149]\n",
            " [ 5.         11.48188355 14.63886462 10.36178172  6.49370282]\n",
            " [ 6.         12.72821111 13.85997618 10.29893556  7.79466919]\n",
            " [ 7.         11.30447324 14.44187734  9.80319394  6.69076554]\n",
            " [ 8.         12.97748237 14.46427201 11.40295478  8.32207341]\n",
            " [ 9.         13.41327909 12.99001591 11.44333505  7.45247558]]\n",
            "(100000, 3)\n",
            "[[4928. 7791. 7791.]\n",
            " [4302. 7448. 7448.]\n",
            " [1005. 8816. 1005.]\n",
            " [1970. 2533. 2533.]\n",
            " [3203. 1186. 1186.]\n",
            " [3057. 3928. 3057.]\n",
            " [7636.  647.  647.]\n",
            " [2843. 9681. 2843.]\n",
            " [1530. 9920. 9920.]\n",
            " [4303. 1455. 1455.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poxCy2Ac1-tO",
        "colab_type": "text"
      },
      "source": [
        "There are **10,000 students** and each one of them has **4 grades**. \n",
        "\n",
        "There are **10,000 comparisons** which have been made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9rxKZgy2veR",
        "colab_type": "text"
      },
      "source": [
        "# Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckMBLFBr21Dy",
        "colab_type": "text"
      },
      "source": [
        "First, we split the grades into **two arrays: grades1 and grades2.** They will represent the grades of the students that appear on the \"compare\" file (we keep the orgininal order).\n",
        "\n",
        "In the same time, we create **a new variable which will the be the target**: its value is **0 if the \"student 1\" was defined by the professors as better than the \"student 2\", and 1 otherwise.**\n",
        "\n",
        "---\n",
        "\n",
        "Thus, the goal is to use the grades arrays (the ones of student 1 and the ones of student 2) as inputs. We will **compute the score for each one with the same weights**, using **a shared layer**. The score will be compute by a linear combination of grades: **a shared layer with a single neuron, without bias and using a linear activation.**\n",
        "\n",
        "**The second (and last) layer will use a sigmoid function** that should return 0 if the \"student 1\" score was higher and 1 otherwise using the y-target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrp_lnj85GDh",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing data and create constraint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCJwWqou-auw",
        "colab_type": "text"
      },
      "source": [
        "We create the two inputs with the values explained above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6bgOxtq7MT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the arrays for students 1 and students 2\n",
        "grades_1 = []\n",
        "grades_2 = []\n",
        "best = []\n",
        "for compare in compare:\n",
        "  grades_1.append(grades[int(compare[0])][1:])\n",
        "  grades_2.append(grades[int(compare[1])][1:])\n",
        "\n",
        "  # adding the comparison for target\n",
        "  if compare[2] == compare[0]:\n",
        "    best.append(0)\n",
        "  else:\n",
        "    best.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIJiT7py-iNE",
        "colab_type": "text"
      },
      "source": [
        "As a reminder, **the constraints on the weights** are :\n",
        "\n",
        "*   each weight should be positive;\n",
        "*   the weights should sum to 1.\n",
        "\n",
        "Thus, we have to create it by our own as it's not a common one taken in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9KTxTiN_Xtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def constraint(w):\n",
        "  return abs(w / (math_ops.reduce_sum(w, axis=0, keepdims=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbGkwGc3-1qm",
        "colab_type": "text"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzdtPCpdC36x",
        "colab_type": "text"
      },
      "source": [
        "As we are facing a classification problem (predict the best student), we will use the binary_crossentropy loss. The accuracy metric will assess the perfomance. We use an adam optimizer.\n",
        "\n",
        "We will use a traditionnal validation split of 20% to test the model in a fairly manner.\n",
        "\n",
        "*Note: restore_best_weights command allows to save the best ones and not the last ones.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl8wjn7T_8iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "student_1 = Input(shape=(4,), dtype='float32', name='student_1') # input with the grades of students 1\n",
        "student_2 = Input(shape=(4,), dtype='float32', name='student_2') # input with the grades of students 2\n",
        "\n",
        "\n",
        "shared_layer = Dense(1,  activation=\"linear\",use_bias=False, kernel_constraint=constraint) # calculating the grades\n",
        "student_1_score = shared_layer(student_1)\n",
        "student_2_score = shared_layer(student_2)\n",
        "\n",
        "preds = Dense(1, activation='sigmoid')(Concatenate(axis=-1)([student_1_score, student_2_score])) # predicting the best student\n",
        "\n",
        "model = Model(inputs=[student_1, student_2], outputs=preds) # building our model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3Ib6g5CG06e",
        "colab_type": "code",
        "outputId": "d8affbda-d91d-4fb4-c803-429d642097cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Testing the model\n",
        "from tensorflow.python.ops import math_ops\n",
        "model.fit([grades_1, grades_2], best, epochs=10, validation_split = .2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80000 samples, validate on 20000 samples\n",
            "Epoch 1/10\n",
            "80000/80000 [==============================] - 12s 145us/step - loss: 1.3297 - acc: 0.5583 - val_loss: 0.6728 - val_acc: 0.6379\n",
            "Epoch 2/10\n",
            "80000/80000 [==============================] - 11s 136us/step - loss: 0.6460 - acc: 0.7059 - val_loss: 0.6072 - val_acc: 0.8266\n",
            "Epoch 3/10\n",
            "80000/80000 [==============================] - 11s 138us/step - loss: 0.5640 - acc: 0.9119 - val_loss: 0.5255 - val_acc: 0.9564\n",
            "Epoch 4/10\n",
            "80000/80000 [==============================] - 11s 144us/step - loss: 0.4986 - acc: 0.9543 - val_loss: 0.4713 - val_acc: 0.9489\n",
            "Epoch 5/10\n",
            "80000/80000 [==============================] - 11s 138us/step - loss: 0.4496 - acc: 0.9598 - val_loss: 0.4262 - val_acc: 0.9696\n",
            "Epoch 6/10\n",
            "80000/80000 [==============================] - 11s 141us/step - loss: 0.4094 - acc: 0.9653 - val_loss: 0.3905 - val_acc: 0.9730\n",
            "Epoch 7/10\n",
            "80000/80000 [==============================] - 12s 144us/step - loss: 0.3768 - acc: 0.9708 - val_loss: 0.3621 - val_acc: 0.9715\n",
            "Epoch 8/10\n",
            "80000/80000 [==============================] - 11s 137us/step - loss: 0.3497 - acc: 0.9728 - val_loss: 0.3340 - val_acc: 0.9740\n",
            "Epoch 9/10\n",
            "80000/80000 [==============================] - 11s 138us/step - loss: 0.3266 - acc: 0.9763 - val_loss: 0.3135 - val_acc: 0.9830\n",
            "Epoch 10/10\n",
            "80000/80000 [==============================] - 11s 138us/step - loss: 0.3076 - acc: 0.9794 - val_loss: 0.2975 - val_acc: 0.9820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7f5245f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJWNrR2kIqfo",
        "colab_type": "text"
      },
      "source": [
        "Our results look great, with a very strong accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFOvxMLHN9a6",
        "colab_type": "text"
      },
      "source": [
        "# Weights inspection and validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K4HWE3uJ6s9",
        "colab_type": "text"
      },
      "source": [
        "We have a look at our weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tX82Y0IhWY",
        "colab_type": "code",
        "outputId": "fbf6d8bb-59c4-473c-e6b1-1d4ccf3cdf72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(shared_layer.get_weights()[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.3267201 ]\n",
            " [0.10893933]\n",
            " [0.30102238]\n",
            " [0.26331815]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF6NBZ3DNjiT",
        "colab_type": "text"
      },
      "source": [
        "They all respect the contraint of being between 0-1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ_AQAvLNe3t",
        "colab_type": "code",
        "outputId": "4727311b-979e-4966-c2c9-1467aab65a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sum(shared_layer.get_weights()[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLInB8NQJ9en",
        "colab_type": "text"
      },
      "source": [
        "They respect the constraint of the sum equals to 1.\n",
        "\n",
        "We can see that the first grade has a strong weight, followed closely by the third and fourth one. The second one has a low weigth.\n",
        "\n",
        "We can deduce that Maths and CS were the most important classes for the professors, followed closely by English. The Economics class is less important. Probably an Engineering School !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR-QuNniKpgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the weights as txt file on my drive\n",
        "np.savetxt(\"/content/gdrive/My Drive/my_weigths.txt\", shared_layer.get_weights()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw1NbmLqPz-O",
        "colab_type": "code",
        "outputId": "2e660eaa-5d2c-4b16-c752-cde9a385251b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content/gdrive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}